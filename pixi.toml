[workspace]
authors = ["boilcy <0x6c6379@gmail.com>"]
channels = ["conda-forge", "pytorch", "nvidia", "cuda"]
name = "qarobo"
platforms = ["win-64", "linux-64", "linux-aarch64"]
version = "0.1.0"

[system-requirements]
cuda = "12.0"

[target.unix.activation.env]
CUDA_HOME="$CONDA_PREFIX"
[target.win-64.activation.env]
CUDA_HOME="%CONDA_PREFIX%"

[target.linux-64.dependencies]
triton = ">=3.3.1,<4"
flash-attn = ">=2.8.3,<3"

[target.linux-aarch64.dependencies]
triton = ">=3.3.1,<4"
flash-attn = ">=2.8.3,<3"

[dependencies]
python = "3.11.*"
pytorch-gpu = ">=2.5.1,<3"
torchaudio = ">=2.5.1,<3"
loguru = ">=0.7.3,<0.8"
numpy = ">=2.2.6,<3"
requests = ">=2.32.5,<3"
transformers = ">=4.56.1,<5"
nltk = ">=3.9.1,<4"
openai = ">=1.107.1,<2"
setuptools = ">=75.8.2,<81"
librosa = ">=0.11.0,<0.12"
pip = ">=25.2,<26"

[pypi-options]
index-url = "https://pypi.tuna.tsinghua.edu.cn/simple"
extra-index-urls = ["https://mirrors.aliyun.com/pypi/simple/"]
no-build-isolation = true

[pypi-dependencies]
misaki = { version = ">=0.9.4, <0.10", extras = ["zh", "en"] }
kokoro = ">=0.9.4, <0.10"
sounddevice = ">=0.5.2, <0.6"

[tasks.server]
cmd = [
    "python",
    "s2s_pipeline.py",
    "--lm_model_name",
    "G:\\projects\\speech-to-speech\\models\\Qwen2.5-3B-Instruct",
    "--stt_model_name",
    "G:\\projects\\qarobo\\models\\whisper-large-v3-turbo",
    "--recv_host", 
    "0.0.0.0",
    "--send_host",
    "0.0.0.0",
    "--language",
    "zh",
    "--tts",
    "kokoro",
    "--init_chat_role",
    "system",
    "--init_chat_prompt",
    "你是一个帮助用户解决问题的助手"
]

[tasks.client]
args = ["host"]
cmd = [
    "python",
    "listen_and_play.py",
    "--host",
    "{{host}}"
]

[tasks.local]
cmd = [
    "python",
    "s2s_pipeline.py",
    "--lm_model_name",
    ".\\models\\Qwen3-0.6B",
    "--stt_model_name",
    ".\\models\\whisper-large-v3-turbo",
    "--mode",
    "local",
    "--language",
    "zh",
    "--tts",
    "kokoro",
]
